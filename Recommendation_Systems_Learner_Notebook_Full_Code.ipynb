{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXQzH0nC5JtP"
   },
   "source": [
    "# **Project: Amazon Product Recommendation System**\n",
    "\n",
    "# **Marks: 60**\n",
    "\n",
    "\n",
    "Welcome to the project on Recommendation Systems. We will work with the Amazon product reviews dataset for this project. The dataset contains ratings of different electronic products. It does not include information about the products or reviews to avoid bias while building the model. \n",
    "\n",
    "--------------\n",
    "## **Context:**\n",
    "--------------\n",
    "\n",
    "Today, information is growing exponentially with volume, velocity and variety throughout the globe. This has lead to information overload, and too many choices for the consumer of any business. It represents a real dilemma for these consumers and they often turn to denial. Recommender Systems are one of the best tools that help recommending products to consumers while they are browsing online. Providing personalized recommendations which is most relevant for the user is what's most likely to keep them engaged and help business. \n",
    "\n",
    "E-commerce websites like Amazon, Walmart, Target and Etsy use different recommendation models to provide personalized suggestions to different users. These companies spend millions of dollars to come up with algorithmic techniques that can provide personalized recommendations to their users.\n",
    "\n",
    "Amazon, for example, is well-known for its accurate selection of recommendations in its online site. Amazon's recommendation system is capable of intelligently analyzing and predicting customers' shopping preferences in order to offer them a list of recommended products. Amazon's recommendation algorithm is therefore a key element in using AI to improve the personalization of its website. For example, one of the baseline recommendation models that Amazon uses is item-to-item collaborative filtering, which scales to massive data sets and produces high-quality recommendations in real-time.\n",
    "\n",
    "----------------\n",
    "## **Objective:**\n",
    "----------------\n",
    "\n",
    "You are a Data Science Manager at Amazon, and have been given the task of building a recommendation system to recommend products to customers based on their previous ratings for other products. You have a collection of labeled data of Amazon reviews of products. The goal is to extract meaningful insights from the data and build a recommendation system that helps in recommending products to online consumers.\n",
    "\n",
    "-----------------------------\n",
    "## **Dataset:** \n",
    "-----------------------------\n",
    "\n",
    "The Amazon dataset contains the following attributes:\n",
    "\n",
    "- **userId:** Every user identified with a unique id\n",
    "- **productId:** Every product identified with a unique id\n",
    "- **Rating:** The rating of the corresponding product by the corresponding user\n",
    "- **timestamp:** Time of the rating. We **will not use this column** to solve the current problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmdPxJ2Q7W7p"
   },
   "source": [
    "**Note:** The code has some user defined functions that will be usefull while making recommendations and measure model performance, you can use these functions or can create your own functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoRfgjS2yekq"
   },
   "source": [
    "Sometimes, the installation of the surprise library, which is used to build recommendation systems, faces issues in Jupyter. To avoid any issues, it is advised to use **Google Colab** for this project.\n",
    "\n",
    "Let's start by mounting the Google drive on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Ibk07-Cyekt"
   },
   "source": [
    "**Installing surprise library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fIt4jcFIm76"
   },
   "source": [
    "## **Importing the necessary libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "jzu2P-TT5JtP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrXYJAv95JtP"
   },
   "source": [
    "### **Loading the data**\n",
    "- Import the Dataset\n",
    "- Add column names ['user_id', 'prod_id', 'rating', 'timestamp']\n",
    "- Drop the column timestamp\n",
    "- Copy the data to another DataFrame called **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "JGb-Hk1B5JtP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset contains 7824482 rows and 4 columns.\n"
     ]
    }
   ],
   "source": [
    "orig = pd.read_csv('ratings_electronics.csv', names=['user_id', 'prod_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Check the number of rows and columns\n",
    "num_rows, num_cols = orig.shape\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(f'The original dataset contains {num_rows} rows and {num_cols} columns.')\n",
    "\n",
    "# Drop the timestamp column as we won't be using it\n",
    "orig = orig.drop('timestamp', axis=1)\n",
    "\n",
    "# Copy the data to another DataFrame called df\n",
    "df = orig.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVQnSG5g_9uX"
   },
   "source": [
    "**As this dataset is very large and has 7,824,482 observations, it is not computationally possible to build a model using this. Moreover, many users have only rated a few products and also some products are rated by very few users. Hence, we can reduce the dataset by considering certain logical assumptions.**\n",
    "\n",
    "Here, we will be taking users who have given at least 50 ratings, and the products that have at least 5 ratings, as when we shop online we prefer to have some number of ratings of a product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "4yt9W7Q32EQQ"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the users\n",
    "users = df.user_id\n",
    "\n",
    "# Create a dictionary from users to their number of ratings\n",
    "ratings_count = dict()\n",
    "\n",
    "for user in users:\n",
    "\n",
    "    # If we already have the user, just add 1 to their rating count\n",
    "    if user in ratings_count:        \n",
    "        ratings_count[user] += 1\n",
    "  \n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[user] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "19XB60dq2EQR"
   },
   "outputs": [],
   "source": [
    "# We want our users to have at least 50 ratings to be considered\n",
    "RATINGS_CUTOFF = 50\n",
    "\n",
    "remove_users = []\n",
    "\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "\n",
    "df = df.loc[ ~ df.user_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "33UzK1D82EQS"
   },
   "outputs": [],
   "source": [
    "# Get the column containing the products\n",
    "prods = df.prod_id\n",
    "\n",
    "# Create a dictionary from products to their number of ratings\n",
    "ratings_count = dict()\n",
    "\n",
    "for prod in prods:\n",
    "    \n",
    "    # If we already have the product, just add 1 to its rating count\n",
    "    if prod in ratings_count:\n",
    "        ratings_count[prod] += 1\n",
    "    \n",
    "    # Otherwise, set their rating count to 1\n",
    "    else:\n",
    "        ratings_count[prod] = 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "u6YE-lUp2EQT"
   },
   "outputs": [],
   "source": [
    "# We want our item to have at least 5 ratings to be considered\n",
    "RATINGS_CUTOFF = 5\n",
    "\n",
    "remove_users = []\n",
    "\n",
    "for user, num_ratings in ratings_count.items():\n",
    "    if num_ratings < RATINGS_CUTOFF:\n",
    "        remove_users.append(user)\n",
    "\n",
    "df_final = df.loc[~ df.prod_id.isin(remove_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "aL1JZ00o5JtQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prod_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>A3LDPF5FMB782Z</td>\n",
       "      <td>1400501466</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>A1A5KUIIIHFF4U</td>\n",
       "      <td>1400501466</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>A2XIOXRRYX0KZY</td>\n",
       "      <td>1400501466</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>AW3LX47IHPFRL</td>\n",
       "      <td>1400501466</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>A1E3OB6QMBKRYZ</td>\n",
       "      <td>1400501466</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id     prod_id  rating\n",
       "1310  A3LDPF5FMB782Z  1400501466     5.0\n",
       "1322  A1A5KUIIIHFF4U  1400501466     1.0\n",
       "1335  A2XIOXRRYX0KZY  1400501466     3.0\n",
       "1451   AW3LX47IHPFRL  1400501466     5.0\n",
       "1456  A1E3OB6QMBKRYZ  1400501466     1.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a few rows of the imported dataset\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuPoy_XfxhXZ"
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0d0bWeG-sVB"
   },
   "source": [
    "### **Shape of the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyBVTRDTyek0"
   },
   "source": [
    "### **Check the number of rows and columns and provide observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "fJ4eQKaY5JtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final dataset contains 65290 rows and 3 columns.\n",
      "Percentage of usable rows: 0.83%\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows and columns\n",
    "num_rows, num_cols = df_final.shape\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(f'The final dataset contains {num_rows} rows and {num_cols} columns.')\n",
    "\n",
    "# Display the first few rows to get an overview of the data\n",
    "df_final.head()\n",
    "\n",
    "# Number of rows in the original dataset\n",
    "original_num_rows = orig.shape[0]\n",
    "\n",
    "# Number of rows in the final dataset\n",
    "final_num_rows = df_final.shape[0]\n",
    "\n",
    "# Calculate the percentage of usable rows\n",
    "usable_percentage = (final_num_rows / original_num_rows) * 100\n",
    "\n",
    "# Print the percentage of usable rows\n",
    "print(f'Percentage of usable rows: {usable_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Slp-fgWQ-sVD"
   },
   "source": [
    "# Most rows not being used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAMWm0nC-sVF"
   },
   "source": [
    "### **Data types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "SVrgMkye5JtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id     object\n",
      "prod_id     object\n",
      "rating     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check Data types and provide observations\n",
    "data_types = df_final.dtypes\n",
    "\n",
    "# Print the data types\n",
    "print(data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTMpOROT-sVG"
   },
   "source": [
    "### **Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "vt-VEjMA5JtQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "prod_id    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df_final.isnull().sum()\n",
    "\n",
    "# Print the number of missing values in each column\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Slp-fgWQ-sVD"
   },
   "source": [
    "# No missing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wETrCg48-sVG"
   },
   "source": [
    "### **Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "tYm30MXR5JtR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    65290.000000\n",
      "mean         4.294808\n",
      "std          0.988915\n",
      "min          1.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          5.000000\n",
      "max          5.000000\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics of 'rating' variable and provide observations\n",
    "rating_summary = df_final['rating'].describe()\n",
    "\n",
    "# Print the summary statistics\n",
    "print(rating_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqW50EIJxhXc"
   },
   "source": [
    "**Most ratings are above 4 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywyFrZIf5JtR"
   },
   "source": [
    "### **Checking the rating distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "QbqhbEVe-sVH"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a bar plot of the rating distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=df_final, palette='viridis')\n",
    "\n",
    "# Set title and labels for the plot\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0jONrQv-sVH"
   },
   "source": [
    "**Ratings are skewed to the high end**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HefpLdLJxhXd"
   },
   "source": [
    "### **Checking the number of unique users and items in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "NbSom7195JtR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows in the dataset: 65290\n",
      "Number of unique user IDs: 1540\n",
      "Number of unique product IDs: 5689\n"
     ]
    }
   ],
   "source": [
    "# Number of total rows in the final dataset\n",
    "total_rows = df_final.shape[0]\n",
    "\n",
    "# Number of unique user IDs\n",
    "unique_users = df_final['user_id'].nunique()\n",
    "\n",
    "# Number of unique product IDs\n",
    "unique_products = df_final['prod_id'].nunique()\n",
    "\n",
    "# Print the results\n",
    "print(f'Total number of rows in the dataset: {total_rows}')\n",
    "print(f'Number of unique user IDs: {unique_users}')\n",
    "print(f'Number of unique product IDs: {unique_products}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfDnhSS4-sVI"
   },
   "source": [
    "### **Users with the most number of ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "n7MX452q5JtR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             user_id  count\n",
      "1287    ADLVFFE4VBT8    295\n",
      "1086  A3OXHLG6DIBRW8    230\n",
      "264   A1ODOGXEYECQQ8    217\n",
      "903   A36K2N527TXXJN    212\n",
      "462   A25C2M3QF9G7OQ    203\n",
      "1209   A680RUE1FDO8B    196\n",
      "431   A22CW0ZHY3NJH8    193\n",
      "333   A1UQBFCERIP7VJ    193\n",
      "1508   AWPODHOB4GFWL    184\n",
      "1051  A3LGT6UZL99IW1    179\n"
     ]
    }
   ],
   "source": [
    "# Top 10 users based on the number of ratings\n",
    "# Group by user_id and count the number of ratings for each user\n",
    "user_ratings_count = df_final.groupby('user_id').size().reset_index(name='count')\n",
    "\n",
    "# Sort the users by the number of ratings in descending order\n",
    "top_users = user_ratings_count.sort_values(by='count', ascending=False).head(10)\n",
    "\n",
    "# Print the top 10 users\n",
    "print(top_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1X2w_jt9-sVI"
   },
   "source": [
    "**5 Users have over 200 ratings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnYTx-Ol-sVg"
   },
   "source": [
    "**Now that we have explored and prepared the data, let's build the first recommendation system.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xYGrGVy5JtS"
   },
   "source": [
    "## **Model 1: Rank Based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "yxZTj1UPxhXh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prod_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5688</th>\n",
       "      <td>B00LGQ6HL8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>B003DZJQQI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>B005FDXF2C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>B00I6CVPVC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>B00B9KOCYA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prod_id  average_rating  rating_count\n",
       "5688  B00LGQ6HL8             5.0             5\n",
       "2302  B003DZJQQI             5.0            14\n",
       "3443  B005FDXF2C             5.0             7\n",
       "5554  B00I6CVPVC             5.0             7\n",
       "4810  B00B9KOCYA             5.0             8"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the average rating for each product\n",
    "product_avg_rating = df_final.groupby('prod_id')['rating'].mean().reset_index(name='average_rating')\n",
    "\n",
    "# Calculate the count of ratings for each product\n",
    "product_rating_count = df_final.groupby('prod_id')['rating'].count().reset_index(name='rating_count')\n",
    "\n",
    "# Merge the average rating and rating count into a single DataFrame\n",
    "final_rating = pd.merge(product_avg_rating, product_rating_count, on='prod_id')\n",
    "\n",
    "# Sort the DataFrame by average rating in descending order\n",
    "final_rating_sorted = final_rating.sort_values(by='average_rating', ascending=False)\n",
    "\n",
    "# Display the first five records of the sorted DataFrame\n",
    "final_rating_sorted.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "zKU__5s1xhXi"
   },
   "outputs": [],
   "source": [
    "def get_top_n_products(df, n=10, min_interactions=5):\n",
    "    # Calculate the average rating for each product\n",
    "    product_avg_rating = df.groupby('prod_id')['rating'].mean().reset_index(name='average_rating')\n",
    "\n",
    "    # Calculate the count of ratings for each product\n",
    "    product_rating_count = df.groupby('prod_id')['rating'].count().reset_index(name='rating_count')\n",
    "\n",
    "    # Merge the average rating and rating count into a single DataFrame\n",
    "    product_stats = pd.merge(product_avg_rating, product_rating_count, on='prod_id')\n",
    "\n",
    "    # Filter products based on the minimum number of interactions\n",
    "    filtered_products = product_stats[product_stats['rating_count'] >= min_interactions]\n",
    "\n",
    "    # Sort the filtered products by average rating in descending order\n",
    "    sorted_products = filtered_products.sort_values(by='average_rating', ascending=False)\n",
    "\n",
    "    # Return the top n products\n",
    "    return sorted_products.head(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8l6373PxhXi"
   },
   "source": [
    "### **Recommending top 5 products with 50 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "dBxdLiM_xhXi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         prod_id  average_rating  rating_count\n",
      "1594  B001TH7GUU        4.871795            78\n",
      "2316  B003ES5ZUU        4.864130           184\n",
      "1227  B0019EHU8G        4.855556            90\n",
      "3877  B006W8U2MU        4.824561            57\n",
      "850   B000QUUFRW        4.809524            84\n"
     ]
    }
   ],
   "source": [
    "# Recommending top 5 products with 50 minimum interactions based on popularity\n",
    "top_5_products = get_top_n_products(df_final, n=5, min_interactions=50)\n",
    "\n",
    "# Display the top 5 products\n",
    "print(top_5_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9_xW_UMxhXj"
   },
   "source": [
    "### **Recommending top 5 products with 100 minimum interactions based on popularity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "dZgGZCUoxhXj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         prod_id  average_rating  rating_count\n",
      "2316  B003ES5ZUU        4.864130           184\n",
      "781   B000N99BBC        4.772455           167\n",
      "2073  B002WE6D44        4.770000           100\n",
      "4126  B007WTAJTO        4.701220           164\n",
      "2041  B002V88HFE        4.698113           106\n"
     ]
    }
   ],
   "source": [
    "# Recommending top 5 products with 100 minimum interactions based on popularity\n",
    "top_5_products_100_interactions = get_top_n_products(df_final, n=5, min_interactions=100)\n",
    "\n",
    "# Display the top 5 products\n",
    "print(top_5_products_100_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BL-m68a15JtT",
    "outputId": "69132b0f-8d3f-4798-f6a0-249e17a3c822"
   },
   "source": [
    "We have recommended the **top 5** products by using the popularity recommendation system. Now, let's build a recommendation system using **collaborative filtering.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJI5kiiGvOOK"
   },
   "source": [
    "## **Model 2: Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skzc0N1_nVNB"
   },
   "source": [
    "### **Building a baseline user-user similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Uo_MYMnVNB"
   },
   "source": [
    "- Below, we are building **similarity-based recommendation systems** using `cosine` similarity and using **KNN to find similar users** which are the nearest neighbor to the given user.  \n",
    "- We will be using a new library, called `surprise`, to build the remaining models. Let's first import the necessary classes and functions from this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "UJ1wEylUpexj"
   },
   "outputs": [],
   "source": [
    "# To compute the accuracy of models\n",
    "from surprise import accuracy\n",
    "\n",
    "# Class is used to parse a file containing ratings, data should be in structure - user ; item ; rating\n",
    "from surprise.reader import Reader\n",
    "\n",
    "# Class for loading datasets\n",
    "from surprise.dataset import Dataset\n",
    "\n",
    "# For tuning model hyperparameters\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# For splitting the rating data in train and test datasets\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# For implementing similarity-based recommendation system\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# For implementing matrix factorization based recommendation system\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# for implementing K-Fold cross-validation\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# For implementing clustering-based recommendation system\n",
    "from surprise import CoClustering\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54MqVAtDTsnl"
   },
   "source": [
    "**Before building the recommendation systems, let's  go over some basic terminologies we are going to use:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsxb3xhnTsnl"
   },
   "source": [
    "**Relevant item:** An item (product in this case) that is actually **rated higher than the threshold rating** is relevant, if the **actual rating is below the threshold then it is a non-relevant item**.  \n",
    "\n",
    "**Recommended item:** An item that's **predicted rating is higher than the threshold is a recommended item**, if the **predicted rating is below the threshold then that product will not be recommended to the user**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyLUHCuTsnl"
   },
   "source": [
    "**False Negative (FN):** It is the **frequency of relevant items that are not recommended to the user**. If the relevant items are not recommended to the user, then the user might not buy the product/item. This would result in the **loss of opportunity for the service provider**, which they would like to minimize.\n",
    "\n",
    "**False Positive (FP):** It is the **frequency of recommended items that are actually not relevant**. In this case, the recommendation system is not doing a good job of finding and recommending the relevant items to the user. This would result in **loss of resources for the service provider**, which they would also like to minimize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yuvc2VaZTsnl"
   },
   "source": [
    "**Recall:** It is the **fraction of actually relevant items that are recommended to the user**, i.e., if out of 10 relevant products, 6 are recommended to the user then recall is 0.60. Higher the value of recall better is the model. It is one of the metrics to do the performance assessment of classification models.\n",
    "\n",
    "**Precision:** It is the **fraction of recommended items that are relevant actually**, i.e., if out of 10 recommended items, 6 are found relevant by the user then precision is 0.60. The higher the value of precision better is the model. It is one of the metrics to do the performance assessment of classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NLc36Y8Tsnm"
   },
   "source": [
    "**While making a recommendation system, it becomes customary to look at the performance of the model. In terms of how many recommendations are relevant and vice-versa, below are some most used performance metrics used in the assessment of recommendation systems.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqF8fRBqTsnm"
   },
   "source": [
    "### **Precision@k, Recall@ k, and F1-score@k**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imMJNF0HTsnm"
   },
   "source": [
    "**Precision@k** - It is the **fraction of recommended items that are relevant in `top k` predictions**. The value of k is the number of recommendations to be provided to the user. One can choose a variable number of recommendations to be given to a unique user.  \n",
    "\n",
    "\n",
    "**Recall@k** - It is the **fraction of relevant items that are recommended to the user in `top k` predictions**.\n",
    "\n",
    "**F1-score@k** - It is the **harmonic mean of Precision@k and Recall@k**. When **precision@k and recall@k both seem to be important** then it is useful to use this metric because it is representative of both of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBW4BUhWTsnm"
   },
   "source": [
    "### **Some useful functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOBHKh0eTsnm"
   },
   "source": [
    "- Below function takes the **recommendation model** as input and gives the **precision@k, recall@k, and F1-score@k** for that model.  \n",
    "- To compute **precision and recall**, **top k** predictions are taken under consideration for each user.\n",
    "- We will use the precision and recall to compute the F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "Rxn-GahOTsnm"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_k(model, k = 10, threshold = 3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user\n",
    "    user_est_true = defaultdict(list)\n",
    "    \n",
    "    # Making predictions on the test data\n",
    "    predictions = model.test(testset)\n",
    "    \n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. Therefore, we are setting Precision to 0 when n_rec_k is 0\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. Therefore, we are setting Recall to 0 when n_rel is 0\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    \n",
    "    # Mean of all the predicted precisions are calculated.\n",
    "    precision = round((sum(prec for prec in precisions.values()) / len(precisions)), 3)\n",
    "    \n",
    "    # Mean of all the predicted recalls are calculated.\n",
    "    recall = round((sum(rec for rec in recalls.values()) / len(recalls)), 3)\n",
    "    \n",
    "    accuracy.rmse(predictions)\n",
    "    \n",
    "    print('Precision: ', precision) # Command to print the overall precision\n",
    "    \n",
    "    print('Recall: ', recall) # Command to print the overall recall\n",
    "    \n",
    "    print('F_1 score: ', round((2*precision*recall)/(precision+recall), 3)) # Formula to compute the F-1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZmsamDVyek-"
   },
   "source": [
    "**Hints:**\n",
    "\n",
    "- To compute **precision and recall**, a **threshold of 3.5 and k value of 10 can be considered for the recommended and relevant ratings**.\n",
    "- Think about the performance metric to choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hxjJMTwnVNB"
   },
   "source": [
    "Below we are loading the **`rating` dataset**, which is a **pandas DataFrame**, into a **different format called `surprise.dataset.DatasetAutoFolds`**, which is required by this library. To do this, we will be **using the classes `Reader` and `Dataset`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "rGfYDiOCpe4X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 48967\n",
      "Number of test samples: 16323\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Assuming df_final is your pandas DataFrame with columns 'user_id', 'prod_id', 'rating'\n",
    "\n",
    "# Step 1: Instantiating Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Step 2: Loading the rating dataset\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Step 3: Splitting the data into train and test datasets\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Verify the splits\n",
    "print(\"Number of training samples:\", trainset.n_ratings)\n",
    "print(\"Number of test samples:\", len(testset))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmHTEt7TnVNC"
   },
   "source": [
    "Now, we are **ready to build the first baseline similarity-based recommendation system** using the cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVDfVHB4tQfU"
   },
   "source": [
    "### **Building the user-user Similarity-based Recommendation System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "vO3FL7iape8A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0116\n",
      "Precision:  0.858\n",
      "Recall:  0.822\n",
      "F_1 score:  0.84\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# Step 1: Declaring the similarity options\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True  # Compute similarities between users\n",
    "}\n",
    "\n",
    "# Step 2: Initialize the KNNBasic model using sim_options, Verbose = False, and setting random_state = 1\n",
    "algo = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Step 3: Fit the model on the training data\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Evaluate the model\n",
    "precision_recall_at_k(algo, k=10, threshold=3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEuJK_A9Tsnn"
   },
   "source": [
    "**1. RMSE (Root Mean Squared Error)\n",
    "Value: 1.0116\n",
    "\n",
    "Explanation:\n",
    "\n",
    "RMSE is a measure of the differences between the predicted ratings and the actual ratings.\n",
    "A lower RMSE value indicates a better fit of the model to the data.\n",
    "An RMSE of 1.0116 suggests that, on average, the predicted ratings are off by about 1.01 points from the actual ratings on the rating scale of 1 to 5.\n",
    "While an RMSE around 1 is fairly common in recommendation systems, further tuning or different algorithms might reduce this error.\n",
    "2. Precision@k\n",
    "Value: 0.858\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Precision@k is the proportion of recommended items in the top k that are actually relevant.\n",
    "In this context, a precision of 0.858 means that 85.8% of the items recommended in the top k (where k=10 in this case) are relevant (i.e., they have an actual rating above the threshold of 3.5).\n",
    "High precision indicates that the model is effective at recommending relevant items, with fewer irrelevant recommendations.\n",
    "3. Recall@k\n",
    "Value: 0.822\n",
    "\n",
    "Explanation:\n",
    "\n",
    "Recall@k is the proportion of relevant items that are found in the top k recommendations.\n",
    "A recall of 0.822 means that 82.2% of the relevant items (those with an actual rating above the threshold of 3.5) are successfully recommended in the top k items.\n",
    "High recall indicates that the model is effective at identifying most of the relevant items, ensuring that users see a large portion of items they would rate highly.\n",
    "4. F1 Score@k\n",
    "Value: 0.84\n",
    "\n",
    "Explanation:\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall, providing a single metric that balances both concerns.\n",
    "An F1 score of 0.84 means the model strikes a good balance between precision and recall.\n",
    "This score indicates that the model is generally good at recommending relevant items while minimizing irrelevant ones, and it captures the trade-off between having a high recall and high precision.\n",
    "Overall Observations\n",
    "Model Performance: The model performs well in terms of both precision and recall, suggesting that it is effective at making accurate recommendations.\n",
    "Trade-off: The F1 score indicates a good balance between precision and recall. This is important because maximizing one metric often leads to a decrease in the other.\n",
    "RMSE Insight: While the RMSE is relatively high, it is important to consider it in conjunction with precision and recall. A high RMSE might indicate that some predictions are significantly off, but it doesn't necessarily mean that the model fails to make useful recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reFD0-nsnVNC"
   },
   "source": [
    "Let's now **predict rating for a user with `userId=A3LDPF5FMB782Z` and `productId=1400501466`** as shown below. Here the user has already interacted or watched the product with productId '1400501466' and given a rating of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "Sxd23bZ9pe_x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.4\n",
      "Actual rating given by the user: 5\n"
     ]
    }
   ],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating\n",
    "prediction = algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction and the actual rating\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')\n",
    "print(f'Actual rating given by the user: 5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENJcqG_wemRH"
   },
   "source": [
    "**Write your observations here:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj6ecbglTsno"
   },
   "source": [
    "Below is the function to find the **list of users who have not seen the product with product id \"1400501466\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_users_not_interacted_with(n, data, prod_id):\n",
    "    users_interacted_with_product = set(data[data['prod_id'] == prod_id]['user_id'])\n",
    "    all_users = set(data['user_id'])\n",
    "    return list(all_users.difference(users_interacted_with_product))[:n] # where n is the number of elements to get in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "xCRBMD-RTsno"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A2UEB48LAWFUCW',\n",
       " 'A2GKMXRLI7KLFP',\n",
       " 'A2QRXQPHDMFCQV',\n",
       " 'A23QII83UGZP5U',\n",
       " 'APQQK1V695AUE']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique user_id where prod_id is not equal to \"1400501466\"\n",
    "n_users_not_interacted_with(5, df_final, '1400501466')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KT42ecaSTsno"
   },
   "source": [
    "* It can be observed from the above list that **user \"A2UOHALGF2X77Q\" has not seen the product with productId \"1400501466\"** as this user id is a part of the above list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXSgq8OEnVNE"
   },
   "source": [
    "**Below we are predicting rating for `userId=A2UOHALGF2X77Q` and `prod_id=1400501466`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "PbFcBj1PpfEV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.4\n",
      "Actual rating given by the user: 5\n"
     ]
    }
   ],
   "source": [
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating\n",
    "prediction = algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction and the actual rating\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')\n",
    "print(f'Actual rating given by the user: 5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02rwld8yemRI"
   },
   "source": [
    "**Off by close to 1.5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejjof6csnVNF"
   },
   "source": [
    "### **Improving similarity-based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2j4VvfQnVNF"
   },
   "source": [
    "Below, we will be tuning hyperparameters for the `KNNBasic` algorithm. Let's try to understand some of the hyperparameters of the KNNBasic algorithm:\n",
    "\n",
    "- **k** (int)  The (max) number of neighbors to take into account for aggregation. Default is 40.\n",
    "- **min_k** (int)  The minimum number of neighbors to take into account for aggregation. If there are not enough neighbors, the prediction is set to the global mean of all ratings. Default is 1.\n",
    "- **sim_options** (dict)  A dictionary of options for the similarity measure. And there are four similarity measures available in surprise - \n",
    "    - cosine\n",
    "    - msd (default)\n",
    "    - Pearson\n",
    "    - Pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "9LmPbSUSTsnp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.9686221254652656\n",
      "Best hyperparameters: {'k': 50, 'min_k': 5, 'sim_options': {'name': 'cosine', 'user_based': True}}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Step 1: Setting up parameter grid to tune the hyperparameters\n",
    "param_grid = {\n",
    "    'k': [20, 30, 40, 50],\n",
    "    'min_k': [1, 5, 10],\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'msd', 'pearson', 'pearson_baseline'],\n",
    "        'user_based': [True]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 2: Performing 3-fold cross-validation to tune the hyperparameters\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Step 3: Fitting the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Step 4: Best RMSE score\n",
    "best_rmse = gs.best_score['rmse']\n",
    "print(f'Best RMSE score: {best_rmse}')\n",
    "\n",
    "# Step 5: Combination of parameters that gave the best RMSE score\n",
    "best_params = gs.best_params['rmse']\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2fHNvu7nVNF"
   },
   "source": [
    "Once the grid search is **complete**, we can get the **optimal values for each of those hyperparameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHWgxu_YnVNG"
   },
   "source": [
    "Now, let's build the **final model by using tuned values of the hyperparameters**, which we received by using **grid search cross-validation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "PujRJA8X_JEJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9571\n",
      "Precision:  0.852\n",
      "Recall:  0.854\n",
      "F_1 score:  0.853\n"
     ]
    }
   ],
   "source": [
    "# Optimal hyperparameters from grid search\n",
    "optimal_params = {\n",
    "    'k': 50,\n",
    "    'min_k': 5,\n",
    "    'sim_options': {\n",
    "        'name': 'cosine',\n",
    "        'user_based': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 1: Creating an instance of KNNBasic with optimal hyperparameter values\n",
    "optimal_algo = KNNBasic(k=optimal_params['k'], \n",
    "                        min_k=optimal_params['min_k'], \n",
    "                        sim_options=optimal_params['sim_options'],\n",
    "                        verbose=False,\n",
    "                        random_state=1)\n",
    "\n",
    "# Step 2: Training the algorithm on the trainset\n",
    "optimal_algo.fit(trainset)\n",
    "\n",
    "# Evaluate the model with optimal hyperparameters\n",
    "precision_recall_at_k(optimal_algo, k=10, threshold=3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHsWvFjKTsnp"
   },
   "source": [
    "**Write your observations here: Initial Results:\n",
    "RMSE: 1.0116\n",
    "Precision: 0.858\n",
    "Recall: 0.822\n",
    "F1-score: 0.84\n",
    "Optimized Results:\n",
    "RMSE: 0.9571\n",
    "Precision: 0.852\n",
    "Recall: 0.854\n",
    "F1-score: 0.853\n",
    "Comparison:\n",
    "RMSE (Root Mean Squared Error):\n",
    "\n",
    "Initial: 1.0116\n",
    "Optimized: 0.9571\n",
    "Observation: The RMSE has decreased from 1.0116 to 0.9571. This indicates that the model's predictions are now closer to the actual ratings, on average. Lower RMSE is better, so this is an improvement.\n",
    "Precision@k:\n",
    "\n",
    "Initial: 0.858\n",
    "Optimized: 0.852\n",
    "Observation: The precision has slightly decreased from 0.858 to 0.852. This means that there is a small reduction in the proportion of recommended items that are relevant. The difference is very minor, indicating the model still maintains high precision.\n",
    "Recall@k:\n",
    "\n",
    "Initial: 0.822\n",
    "Optimized: 0.854\n",
    "Observation: The recall has increased from 0.822 to 0.854. This means that the model is now better at identifying relevant items among the top recommendations. Higher recall is better, so this is a significant improvement.\n",
    "F1-score@k:\n",
    "\n",
    "Initial: 0.84\n",
    "Optimized: 0.853\n",
    "Observation: The F1-score has increased from 0.84 to 0.853. Since F1-score is the harmonic mean of precision and recall, this indicates an overall improvement in the balance between precision and recall.\n",
    "Summary:\n",
    "The optimized model has a lower RMSE and a higher recall compared to the initial model, which indicates that it is making more accurate predictions and identifying more relevant items among the recommendations.\n",
    "Although the precision has slightly decreased, the drop is minimal and does not significantly impact the overall performance.\n",
    "The F1-score has improved, showing that the optimized model has a better balance between precision and recall.\n",
    "Conclusion:\n",
    "The hyperparameter tuning has improved the model's performance overall, especially in terms of RMSE and recall, while maintaining a high level of precision. This suggests that the optimized model is better at making accurate recommendations and identifying relevant items for the users. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhcAXK0CnVNG"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A2UOHALGF2X77Q\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "FgV63lHiq1TV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.4\n",
      "Actual rating given by the user: 5\n"
     ]
    }
   ],
   "source": [
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the optimized model\n",
    "prediction = optimal_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')\n",
    "print(f'Actual rating given by the user: 5')  # Assuming the actual rating is known and is 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5i-OPprNF2e"
   },
   "source": [
    "**Still off by 1.5, **____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_zwO_FnVNH"
   },
   "source": [
    "### **Identifying similar users to a given user (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2QsfqhanVNH"
   },
   "source": [
    "We can also find out **similar users to a given user** or its **nearest neighbors** based on this KNNBasic algorithm. Below, we are finding the 5 most similar users to the first user in the list with internal id 0, based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "TbFle7cKmBJG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar users to user A3LDPF5FMB782Z are: ['A1RPJHUVVSI98A', 'A2L0F2T1DLTNT8', 'A680RUE1FDO8B', 'A1V4A5U5O3TMMD', 'AAQ9NJ480N9W5']\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "from collections import defaultdict\n",
    "from surprise import accuracy\n",
    "\n",
    "# Assuming df_final is your pandas DataFrame with columns 'user_id', 'prod_id', 'rating'\n",
    "\n",
    "# Step 1: Instantiating Reader scale with expected rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Step 2: Loading the rating dataset\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Step 3: Splitting the data into train and test datasets\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Step 4: Declaring the similarity options\n",
    "sim_options = {\n",
    "    'name': 'msd',  # Using mean squared difference for similarity metric\n",
    "    'user_based': True  # Compute similarities between users\n",
    "}\n",
    "\n",
    "# Step 5: Initialize the KNNBasic model using sim_options\n",
    "algo = KNNBasic(sim_options=sim_options, verbose=False, random_state=1)\n",
    "\n",
    "# Step 6: Fit the model on the training data\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Define the user ID for which we want to find similar users\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "\n",
    "# Convert the raw user ID to the internal ID used by the surprise library\n",
    "user_inner_id = algo.trainset.to_inner_uid(user_id)\n",
    "\n",
    "# Find the 5 nearest neighbors\n",
    "similar_users = algo.get_neighbors(user_inner_id, k=5)\n",
    "\n",
    "# Convert the internal IDs of the neighbors back to the raw user IDs\n",
    "similar_user_ids = [algo.trainset.to_raw_uid(inner_id) for inner_id in similar_users]\n",
    "\n",
    "# Display the similar users\n",
    "print(f'The 5 most similar users to user {user_id} are: {similar_user_ids}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0NsrX_anVNH"
   },
   "source": [
    "### **Implementing the recommendation algorithm based on optimized KNNBasic model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3ESobDynVNI"
   },
   "source": [
    "Below we will be implementing a function where the input parameters are:\n",
    "\n",
    "- data: A **rating** dataset\n",
    "- user_id: A user id **against which we want the recommendations**\n",
    "- top_n: The **number of products we want to recommend**\n",
    "- algo: the algorithm we want to use **for predicting the ratings**\n",
    "- The output of the function is a **set of top_n items** recommended for the given user_id based on the given algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "vW9V1Tk65HlY"
   },
   "outputs": [],
   "source": [
    "def get_recommendations(data, user_id, top_n, algo):\n",
    "    \n",
    "    # Creating an empty list to store the recommended product ids\n",
    "    recommendations = []\n",
    "    \n",
    "    # Creating an user item interactions matrix \n",
    "    user_item_interactions_matrix = data.pivot(index = 'user_id', columns = 'prod_id', values = 'rating')\n",
    "    \n",
    "    # Extracting those product ids which the user_id has not interacted yet\n",
    "    non_interacted_products = user_item_interactions_matrix.loc[user_id][user_item_interactions_matrix.loc[user_id].isnull()].index.tolist()\n",
    "    \n",
    "    # Looping through each of the product ids which user_id has not interacted yet\n",
    "    for item_id in non_interacted_products:\n",
    "        \n",
    "        # Predicting the ratings for those non interacted product ids by this user\n",
    "        est = algo.predict(user_id, item_id).est\n",
    "        \n",
    "        # Appending the predicted ratings\n",
    "        recommendations.append((item_id, est))\n",
    "\n",
    "    # Sorting the predicted ratings in descending order\n",
    "    recommendations.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    return recommendations[:top_n] # Returing top n highest predicted rating products for this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj_S7kh4nVNI"
   },
   "source": [
    "**Predicting top 5 products for userId = \"A3LDPF5FMB782Z\" with similarity based recommendation system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "qWbR85mI5Hrk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user A3LDPF5FMB782Z:\n",
      "Product ID: B000067RT6, Predicted Rating: 5\n",
      "Product ID: B001ENW61I, Predicted Rating: 5\n",
      "Product ID: B001TH7GUU, Predicted Rating: 5\n",
      "Product ID: B002WE6D44, Predicted Rating: 5\n",
      "Product ID: B0043WJRRS, Predicted Rating: 5\n"
     ]
    }
   ],
   "source": [
    "# Define the user ID and the number of top recommendations to return\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "top_n = 5\n",
    "\n",
    "# Get the top 5 recommendations for the user\n",
    "top_recommendations = get_recommendations(df_final, user_id, top_n, optimal_algo)\n",
    "\n",
    "# Display the top recommendations\n",
    "print(f'Top {top_n} recommendations for user {user_id}:')\n",
    "for product_id, predicted_rating in top_recommendations:\n",
    "    print(f'Product ID: {product_id}, Predicted Rating: {predicted_rating}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "b5WfIX0Z6_q2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prod_id  predicted_ratings\n",
      "0  B000067RT6                  5\n",
      "1  B001ENW61I                  5\n",
      "2  B001TH7GUU                  5\n",
      "3  B002WE6D44                  5\n",
      "4  B0043WJRRS                  5\n"
     ]
    }
   ],
   "source": [
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "# Create a DataFrame for the recommendations\n",
    "recommendations_df = pd.DataFrame(top_recommendations, columns=['prod_id', 'predicted_ratings'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(recommendations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgbzJKk7Tsnr"
   },
   "source": [
    "### **Item-Item Similarity-based Collaborative Filtering Recommendation System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTJu_2hcTsnr"
   },
   "source": [
    "* Above we have seen **similarity-based collaborative filtering** where similarity is calculated **between users**. Now let us look into similarity-based collaborative filtering where similarity is seen **between items**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "W5RMcdzjTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar users to user A3LDPF5FMB782Z are: ['A3094EPI56GKZ6', 'AGVWTYW0ULXHT', 'A1MCH5RXDOH87H', 'A1RPJHUVVSI98A', 'A2L0F2T1DLTNT8']\n"
     ]
    }
   ],
   "source": [
    "# Define the user ID for which we want to find similar users\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "\n",
    "# Convert the raw user ID to the internal ID used by the surprise library\n",
    "user_inner_id = optimal_algo.trainset.to_inner_uid(user_id)\n",
    "\n",
    "# Find the 5 nearest neighbors\n",
    "similar_users = optimal_algo.get_neighbors(user_inner_id, k=5)\n",
    "\n",
    "# Convert the internal IDs of the neighbors back to the raw user IDs\n",
    "similar_user_ids = [optimal_algo.trainset.to_raw_uid(inner_id) for inner_id in similar_users]\n",
    "\n",
    "# Display the similar users\n",
    "print(f'The 5 most similar users to user {user_id} are: {similar_user_ids}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFbcDQmxTsns"
   },
   "source": [
    "Let's now **predict a rating for a user with `userId = A3LDPF5FMB782Z` and `prod_Id = 1400501466`** as shown below. Here the user has already interacted or watched the product with productId \"1400501466\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "JsF-aaWYTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 3.4\n"
     ]
    }
   ],
   "source": [
    "# Predicting rating for a sample user with an interacted product\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the optimized model\n",
    "prediction = optimal_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h0OyDMFTsns"
   },
   "source": [
    "**Write your observations here:**____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqKGZoAtTsns"
   },
   "source": [
    "Below we are **predicting rating for the `userId = A2UOHALGF2X77Q` and `prod_id = 1400501466`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "5yILOxXRTsns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A2UOHALGF2X77Q and product 1400501466: 4.292339739007903\n"
     ]
    }
   ],
   "source": [
    "# Predicting rating for a sample user with a non interacted product\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A2UOHALGF2X77Q'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the optimized model\n",
    "prediction = optimal_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDKaAveJTsns"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meSvpNLj_EjD"
   },
   "source": [
    "### **Hyperparameter tuning the item-item similarity-based model**\n",
    "- Use the following values for the param_grid and tune the model.\n",
    "  - 'k': [10, 20, 30]\n",
    "  - 'min_k': [3, 6, 9]\n",
    "  - 'sim_options': {'name': ['msd', 'cosine']\n",
    "  - 'user_based': [False]\n",
    "- Use GridSearchCV() to tune the model using the 'rmse' measure\n",
    "- Print the best score and best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "f5bcZ3HgTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.9751433345773899\n",
      "Best hyperparameters: {'k': 30, 'min_k': 6, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30],\n",
    "    'min_k': [3, 6, 9],\n",
    "    'sim_options': {\n",
    "        'name': ['msd', 'cosine'],\n",
    "        'user_based': [False]  # Use item-item similarity\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "\n",
    "# Load the data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "gs.fit(data)\n",
    "\n",
    "# Print the best RMSE score\n",
    "best_rmse = gs.best_score['rmse']\n",
    "print(f'Best RMSE score: {best_rmse}')\n",
    "\n",
    "# Print the combination of parameters that gave the best RMSE score\n",
    "best_params = gs.best_params['rmse']\n",
    "print(f'Best hyperparameters: {best_params}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1psOlx6zTsnt"
   },
   "source": [
    "Once the **grid search** is complete, we can get the **optimal values for each of those hyperparameters as shown above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrSTaQemTsnt"
   },
   "source": [
    "Now let's build the **final model** by using **tuned values of the hyperparameters** which we received by using grid search cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOS9Dwnd_LN6"
   },
   "source": [
    "### **Use the best parameters from GridSearchCV to build the optimized item-item similarity-based model. Compare the performance of the optimized model with the baseline model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "dSeiM1qeTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9677\n",
      "Precision:  0.836\n",
      "Recall:  0.838\n",
      "F_1 score:  0.837\n"
     ]
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.knns import KNNBasic\n",
    "\n",
    "# Best hyperparameters from grid search\n",
    "best_params = {'k': 30, 'min_k': 6, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
    "\n",
    "# Create a new KNNBasic model using the best hyperparameters\n",
    "best_algo = KNNBasic(k=best_params['k'], \n",
    "                     min_k=best_params['min_k'], \n",
    "                     sim_options=best_params['sim_options'],\n",
    "                     verbose=False)\n",
    "\n",
    "# Train the model on the entire dataset (or on the trainset if using a train-test split)\n",
    "best_algo.fit(trainset)\n",
    "precision_recall_at_k(best_algo, k=10, threshold=3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCXKnMI8Tsnt"
   },
   "source": [
    "Observations:\n",
    "RMSE (Root Mean Squared Error):\n",
    "\n",
    "Optimized KNNBasic: 0.9677\n",
    "Original Item-Item Similarity: 0.9751\n",
    "Observation: The optimized KNNBasic model has a slightly lower RMSE compared to the original item-item similarity model, indicating slightly better prediction accuracy.\n",
    "Precision@k:\n",
    "\n",
    "Optimized KNNBasic: 0.836\n",
    "Original Item-Item Similarity: 0.852\n",
    "Observation: The original item-item similarity model has higher precision compared to the optimized KNNBasic model. This means that the original item-item similarity model is better at recommending relevant items.\n",
    "Recall@k:\n",
    "\n",
    "Optimized KNNBasic: 0.838\n",
    "Original Item-Item Similarity: 0.854\n",
    "Observation: The original item-item similarity model has higher recall compared to the optimized KNNBasic model. This indicates that the original item-item similarity model captures more relevant items.\n",
    "F1-score@k:\n",
    "\n",
    "Optimized KNNBasic: 0.837\n",
    "Original Item-Item Similarity: 0.853\n",
    "Observation: The original item-item similarity model has a higher F1-score compared to the optimized KNNBasic model, indicating a better balance between precision and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sbcj_H94Tsnt"
   },
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A2UOHALGF2X77Q\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "gIBRRvdoTsnt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 4.675094816687737\n"
     ]
    }
   ],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the optimized item-item similarity model\n",
    "prediction = best_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A2UOHALGF2X77Q and product 1400501466: 4.292339739007903\n"
     ]
    }
   ],
   "source": [
    "# Use sim_item_item_optimized model to recommend for userId \"A2UOHALGF2X77Q\" and productId \"1400501466\"\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A2UOHALGF2X77Q'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the best model\n",
    "prediction = best_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your observations here: The predictions are much closer to the actual results, optimizing really changes the prediction by almost a whole number*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDlNB7tnTsnu"
   },
   "source": [
    "### **Identifying similar items to a given item (nearest neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLdDiFA6Tsnu"
   },
   "source": [
    "We can also find out **similar items** to a given item or its nearest neighbors based on this **KNNBasic algorithm**. Below we are finding the 5 most similar items to the item with internal id 0 based on the `msd` distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRJS4oDFTsnu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting top 5 products for userId = \"A1A5KUIIIHFF4U\" with similarity based recommendation system.**\n",
    "\n",
    "**Hint:** Use the get_recommendations() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "rzoEbuZFTsnu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most similar items to item with internal id 0 are: ['B008X9Z3UC', 'B003ZSHKJ8', 'B003LSTD38', 'B005EOWBKE', 'B004IZN3WU']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model on the trainset\n",
    "best_algo.fit(trainset)\n",
    "\n",
    "# Define the item ID for which we want to find similar items (internal ID 0)\n",
    "item_inner_id = 0\n",
    "\n",
    "# Find the 5 nearest neighbors\n",
    "similar_items = best_algo.get_neighbors(item_inner_id, k=5)\n",
    "\n",
    "# Convert the internal IDs of the neighbors back to the raw item IDs\n",
    "similar_item_ids = [best_algo.trainset.to_raw_iid(inner_id) for inner_id in similar_items]\n",
    "\n",
    "# Display the similar items\n",
    "print(f'The 5 most similar items to item with internal id {item_inner_id} are: {similar_item_ids}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "_kXVTiysTsnv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      prod_id  predicted_ratings\n",
      "0  B00005OQMO                  5\n",
      "1  B000233WJ6                  5\n",
      "2  B000ESN9GA                  5\n",
      "3  B000PTFDYO                  5\n",
      "4  B0012IJYZQ                  5\n"
     ]
    }
   ],
   "source": [
    "top_recommendations = get_recommendations(df_final, user_id, top_n, sim_item_item_optimized)\n",
    "\n",
    "# Building the dataframe for above recommendations with columns \"prod_id\" and \"predicted_ratings\"\n",
    "# Create a DataFrame for the recommendations\n",
    "recommendations_df = pd.DataFrame(top_recommendations, columns=['prod_id', 'predicted_ratings'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(recommendations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHzmYvs0Tsnv"
   },
   "source": [
    "Now as we have seen **similarity-based collaborative filtering algorithms**, let us now get into **model-based collaborative filtering algorithms**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKgJpSA9vOOL"
   },
   "source": [
    "### **Model 3: Model-Based Collaborative Filtering - Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YF6ZGyqhCAob"
   },
   "source": [
    "Model-based Collaborative Filtering is a **personalized recommendation system**, the recommendations are based on the past behavior of the user and it is not dependent on any additional information. We use **latent features** to find recommendations for each user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4Otha8ovOOL"
   },
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sGl3QkLvOOL"
   },
   "source": [
    "SVD is used to **compute the latent features** from the **user-item matrix**. But SVD does not work when we **miss values** in the **user-item matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "07-2PT5Ssjqm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8944\n",
      "Precision:  0.857\n",
      "Recall:  0.84\n",
      "F_1 score:  0.848\n"
     ]
    }
   ],
   "source": [
    "# Using SVD matrix factorization. Use random_state = 1\n",
    "\n",
    "# Training the algorithm on the trainset\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "\n",
    "from surprise import SVD\n",
    "\n",
    "# Create an SVD model with random_state=1\n",
    "svd_algo = SVD(random_state=1)\n",
    "\n",
    "# Train the model on the trainset\n",
    "svd_algo.fit(trainset)\n",
    "\n",
    "precision_recall_at_k(svd_algo, k=10, threshold=3.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6fTuCDnVNL"
   },
   "source": [
    "**  The SVD model outperforms the item-item similarity model in terms of RMSE and precision, making it more accurate and slightly better at recommending relevant items.\n",
    "The item-item similarity model performs marginally better in terms of recall and F1-score, indicating slightly better coverage of relevant items and a better balance between precision and recall.\n",
    "Overall, the SVD model demonstrates stronger performance in terms of prediction accuracy (RMSE) and relevance (precision), while the item-item similarity model has a slight edge in terms of coverage (recall) and balance (F1-score). Depending on the specific goals and priorities of your recommendation system, you might choose to prioritize one model over the other or consider combining their strengths in a hybrid approach. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's now predict the rating for a user with `userId = \"A3LDPF5FMB782Z\"` and `prod_id = \"1400501466`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "yWIhfdxXsjqm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 4.065602767370937\n"
     ]
    }
   ],
   "source": [
    "# Making prediction\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the trained SVD model\n",
    "prediction = svd_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIjzqDY5nVNM"
   },
   "source": [
    "** Better than SVD without optimized, but worse when optimized.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1aYxVeMnVNM"
   },
   "source": [
    "**Below we are predicting rating for the `userId = \"A2UOHALGF2X77Q\"` and `productId = \"1400501466\"`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "APm-uMSvcAMf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A2UOHALGF2X77Q and product 1400501466: 4.121299032247267\n"
     ]
    }
   ],
   "source": [
    "# Making prediction\n",
    "# Define the user ID and product ID for prediction\n",
    "user_id = 'A2UOHALGF2X77Q'\n",
    "product_id = '1400501466'\n",
    "\n",
    "# Predict the rating using the trained SVD model\n",
    "prediction = svd_algo.predict(user_id, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Predicted rating for user {user_id} and product {product_id}: {prediction.est}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEL6dy3wnVNM"
   },
   "source": [
    "** Still better than item based without hyper tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x13Eb9Owvpcw"
   },
   "source": [
    "### **Improving Matrix Factorization based recommendation system by tuning its hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQcDPhhcnVNN"
   },
   "source": [
    "Below we will be tuning only three hyperparameters:\n",
    "- **n_epochs**: The number of iterations of the SGD algorithm.\n",
    "- **lr_all**: The learning rate for all parameters.\n",
    "- **reg_all**: The regularization term for all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "4bM81V_hvtwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.9004996056451867\n",
      "Best hyperparameters: {'n_epochs': 20, 'lr_all': 0.01, 'reg_all': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Set the parameter space to tune\n",
    "\n",
    "# Performing 3-fold gridsearch cross-validation\n",
    "\n",
    "# Fitting data\n",
    "\n",
    "# Best RMSE score\n",
    "\n",
    "# Combination of parameters that gave the best RMSE score\n",
    "\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_epochs': [10, 20, 30],       # Number of iterations of the SGD algorithm\n",
    "    'lr_all': [0.002, 0.005, 0.01],  # Learning rate for all parameters\n",
    "    'reg_all': [0.02, 0.1, 0.2]     # Regularization term for all parameters\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, n_jobs=-1)\n",
    "# Load the data\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df_final[['user_id', 'prod_id', 'rating']], reader)\n",
    "\n",
    "# Perform the grid search cross-validation\n",
    "gs.fit(data)\n",
    "\n",
    "# Print the best RMSE score\n",
    "best_rmse = gs.best_score['rmse']\n",
    "print(f'Best RMSE score: {best_rmse}')\n",
    "\n",
    "# Print the combination of parameters that gave the best RMSE score\n",
    "best_params = gs.best_params['rmse']\n",
    "print(f'Best hyperparameters: {best_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzY78HsrnVNO"
   },
   "source": [
    "Now, we will **the build final model** by using **tuned values** of the hyperparameters, which we received using grid search cross-validation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "TA_7xe-nnhuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8854\n",
      "Precision:  0.857\n",
      "Recall:  0.838\n",
      "F_1 score:  0.847\n"
     ]
    }
   ],
   "source": [
    "# Build the optimized SVD model using optimal hyperparameter search. Use random_state=1\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "\n",
    "# Use the function precision_recall_at_k to compute precision@k, recall@k, F1-Score, and RMSE\n",
    "\n",
    "svd_optimized = SVD(n_epochs=20, lr_all=0.01, reg_all=0.2, random_state=1)\n",
    "\n",
    "# Train the model on the trainset\n",
    "svd_optimized.fit(trainset)\n",
    "\n",
    "# Evaluate the optimized SVD model\n",
    "precision_recall_at_k(svd_optimized, k=10, threshold=3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HJvPsjITsny"
   },
   "source": [
    "**Write your observations here: \n",
    "RMSE (Root Mean Squared Error):\n",
    "\n",
    "Optimized SVD: 0.8854\n",
    "Initial SVD: 0.8944\n",
    "Item-Item Similarity: 0.9751\n",
    "Observation: The optimized SVD model has the lowest RMSE, indicating the highest prediction accuracy among the three models. It has improved compared to both the initial SVD and item-item similarity models.\n",
    "Precision@k:\n",
    "\n",
    "Optimized SVD: 0.857\n",
    "Initial SVD: 0.857\n",
    "Item-Item Similarity: 0.852\n",
    "Observation: The precision of the optimized SVD model remains the same as the initial SVD model and is slightly higher than the item-item similarity model. This indicates that the optimized SVD model is equally good at recommending relevant items as the initial SVD model and slightly better than the item-item similarity model.\n",
    "Recall@k:\n",
    "\n",
    "Optimized SVD: 0.838\n",
    "Initial SVD: 0.84\n",
    "Item-Item Similarity: 0.854\n",
    "Observation: The recall of the optimized SVD model is slightly lower than the initial SVD model and the item-item similarity model. This means the optimized SVD model captures a slightly lower proportion of relevant items compared to the other two models.\n",
    "F1-score@k:\n",
    "\n",
    "Optimized SVD: 0.847\n",
    "Initial SVD: 0.848\n",
    "Item-Item Similarity: 0.853\n",
    "Observation: The F1-score of the optimized SVD model is slightly lower than the initial SVD model and the item-item similarity model, reflecting the slightly lower recall. However, the precision remains high, which keeps the F1-score competitive.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Steps:**\n",
    "- **Predict rating for the user with `userId=\"A3LDPF5FMB782Z\"`, and `prod_id= \"1400501466\"` using the optimized model**\n",
    "- **Predict rating for `userId=\"A2UOHALGF2X77Q\"` who has not interacted with `prod_id =\"1400501466\"`, by using the optimized model**\n",
    "- **Compare the output with the output from the baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized SVD: Predicted rating for user A3LDPF5FMB782Z and product 1400501466: 4.12496037773697\n"
     ]
    }
   ],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A3LDPF5FMB782Z\" and productId \"1400501466\"\n",
    "# Predict the rating using the optimized SVD model\n",
    "user_id_1 = 'A3LDPF5FMB782Z'\n",
    "product_id = '1400501466'\n",
    "\n",
    "prediction_optimized_1 = svd_optimized.predict(user_id_1, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Optimized SVD: Predicted rating for user {user_id_1} and product {product_id}: {prediction_optimized_1.est}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized SVD: Predicted rating for user A2UOHALGF2X77Q and product 1400501466: 4.085462099600086\n"
     ]
    }
   ],
   "source": [
    "# Use svd_algo_optimized model to recommend for userId \"A2UOHALGF2X77Q\" and productId \"1400501466\"\n",
    "# Predict the rating using the optimized SVD model\n",
    "user_id_2 = 'A2UOHALGF2X77Q'\n",
    "\n",
    "prediction_optimized_2 = svd_optimized.predict(user_id_2, product_id)\n",
    "\n",
    "# Display the prediction\n",
    "print(f'Optimized SVD: Predicted rating for user {user_id_2} and product {product_id}: {prediction_optimized_2.est}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnwPwgjB8DwS"
   },
   "source": [
    "### **Conclusion and Recommendations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuqnifw9NF2p"
   },
   "source": [
    "Recommendations:\n",
    "Primary Goal: Recommendation Quality\n",
    "\n",
    "If the primary goal is to recommend as many relevant items as possible with a good balance between precision and recall, the original item-item similarity model is a strong choice. However, the initial SVD model and optimized SVD model also perform exceptionally well and should be considered.\n",
    "\n",
    "Primary Goal: Prediction Accuracy\n",
    "\n",
    "If prediction accuracy (RMSE) is the priority, the optimized SVD model is the best choice due to its lowest RMSE. The initial SVD model also performs well and can be considered as a close alternative.\n",
    "Hybrid Approach\n",
    "\n",
    "Consider combining the strengths of multiple models in a hybrid approach. For example, the hybrid model could leverage the prediction accuracy of the optimized SVD model and the recommendation quality of the original item-item similarity model and initial SVD model to provide a balanced and robust recommendation system.\n",
    "Further Tuning and Experimentation\n",
    "\n",
    "Further tuning of hyperparameters for all models could be explored to potentially improve their performance. Experimenting with different similarity measures, regularization terms, and learning rates might yield better results.\n",
    "Additional Metrics and Evaluation\n",
    "\n",
    "Consider evaluating additional metrics such as user satisfaction, business impact, and computational efficiency to get a comprehensive understanding of the models' performance in a real-world scenario. Metrics like Mean Absolute Error (MAE), coverage, and diversity of recommendations can provide deeper insights into the models' effectiveness.\n",
    "Continuous Monitoring and Feedback\n",
    "\n",
    "Implement continuous monitoring and user feedback mechanisms to evaluate the performance of the recommendation system in a live environment. This will help in identifying areas for improvement and adapting the system based on user preferences and behavior.\n",
    "Final Decision:\n",
    "Based on the current evaluation, the optimized SVD model is recommended for scenarios where prediction accuracy is paramount. It offers the lowest RMSE and maintains high precision, making it the top performer overall.\n",
    "For scenarios prioritizing recommendation quality and balance between precision and recall, the original item-item similarity model and the initial SVD model are excellent choices.\n",
    "The optimized KNNBasic model performs well but is slightly behind the other models in terms of precision, recall, and F1-score.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
